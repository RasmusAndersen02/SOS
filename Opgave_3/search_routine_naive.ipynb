{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e553d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dir_path = './Korpus'\n",
    "df_file = pd.DataFrame(columns=['file', 'content'])\n",
    "\n",
    "for file_path in glob.glob(os.path.join(dir_path, '*.txt')):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        df_file.loc[len(df_file)] = [file_name, file.read()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569e70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard = {\n",
    "    'sår diabetes': {\n",
    "        'Hælsår.txt',\n",
    "        'Neuropatiske og neuroiskæmiske sår.txt',\n",
    "        'Charcotfod.txt',\n",
    "        'Diabetisk neuropati.txt',\n",
    "        'Behandling for diabetes 2.txt',\n",
    "        'Netdoktor.txt'\n",
    "    },\n",
    "    'livsstilssygdom': {\n",
    "        'Livsstil.txt',\n",
    "        'Risiko.txt',\n",
    "        'Behandling for diabetes 2.txt',\n",
    "        'Motion.txt',\n",
    "        'Mad.txt',\n",
    "        'Diabetes hos børn.txt'\n",
    "    },\n",
    "    'type 2-diabetes': {\n",
    "        'Behandling for diabetes 2.txt',\n",
    "        'Risiko.txt',\n",
    "        'Motion.txt',\n",
    "        'Mad.txt',\n",
    "        'Livsstil.txt',\n",
    "        'Diabetisk neuropati.txt'\n",
    "    },\n",
    "    'kost sukkersyge': {\n",
    "        'Mad.txt',\n",
    "        'Behandling for diabetes 2.txt',\n",
    "        'Livsstil.txt',\n",
    "        'Risiko.txt',\n",
    "        'Motion.txt',\n",
    "        'Diabetes hos børn.txt'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchRoutine (input):\n",
    "    files = []\n",
    "    for idx, row in df_file.iterrows():\n",
    "        if input.lower() in row['content'].lower():\n",
    "            files.append(row['file'])\n",
    "    return files\n",
    "        \n",
    "baseline_results = {}\n",
    "\n",
    "for query in gold_standard:\n",
    "    baseline_results[query] = SearchRoutine(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc9f5421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sår diabetes: Precision=0.00, Recall=0.00, F1=0.00\n",
      "livsstilssygdom: Precision=1.00, Recall=0.17, F1=0.29\n",
      "type 2-diabetes: Precision=0.50, Recall=0.17, F1=0.25\n",
      "kost sukkersyge: Precision=0.00, Recall=0.00, F1=0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def EvalQuary(gold_set, retrieved_list):\n",
    "    retrieved_clean = [doc for doc in retrieved_list if doc is not None]\n",
    "\n",
    "    # Union of all docs involved\n",
    "    comparison_set = list(set(gold_set) | set(retrieved_clean))\n",
    "\n",
    "    gold_vector = [1 if doc in gold_set else 0 for doc in comparison_set]\n",
    "    retrieved_vector = [1 if doc in retrieved_clean else 0 for doc in comparison_set]\n",
    "\n",
    "    precision = precision_score(gold_vector, retrieved_vector, zero_division=0)\n",
    "    recall = recall_score(gold_vector, retrieved_vector, zero_division=0)\n",
    "    f1 = f1_score(gold_vector, retrieved_vector, zero_division=0)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "scores = []\n",
    "\n",
    "for query in gold_standard:\n",
    "    gold = gold_standard[query]\n",
    "    retrieved = baseline_results.get(query, [])\n",
    "\n",
    "    precision, recall, f1 = EvalQuary(gold, retrieved)\n",
    "    scores.append((query, precision, recall, f1))\n",
    "\n",
    "    print(f\"{query}: Precision={precision:.2f}, Recall={recall:.2f}, F1={f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf788fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Scores (Top 6 only):\n",
      "Precision: 0.38\n",
      "Recall:    0.08\n",
      "F1 Score:  0.13\n"
     ]
    }
   ],
   "source": [
    "avg_precision = np.mean([s[1] for s in scores])\n",
    "avg_recall = np.mean([s[2] for s in scores])\n",
    "avg_f1 = np.mean([s[3] for s in scores])\n",
    "\n",
    "print(\"\\nAverage Scores (Top 6 only):\")\n",
    "print(f\"Precision: {avg_precision:.2f}\")\n",
    "print(f\"Recall:    {avg_recall:.2f}\")\n",
    "print(f\"F1 Score:  {avg_f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
